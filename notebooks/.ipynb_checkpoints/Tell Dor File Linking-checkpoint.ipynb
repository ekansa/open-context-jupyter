{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Get the root_path for this jupyter notebook repo.\n",
    "repo_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "\n",
    "# Path to the Tell Dor file metadata CSV\n",
    "path_files = os.path.join(\n",
    "    repo_path, 'files', 'tell-dor', 'tell-dor-files.csv'\n",
    ")\n",
    "# Path to the Tell Dor locus metadata CSV \n",
    "path_loci = os.path.join(\n",
    "    repo_path, 'files', 'tell-dor', 'tell-dor-loci.csv'\n",
    ")\n",
    "# Output path for associations between the files and the loci.\n",
    "path_files_contexts = os.path.join(\n",
    "    repo_path, 'files', 'tell-dor', 'tell-dor-files-contexts.csv'\n",
    ")\n",
    "\n",
    "# Read the file metadata CSV into dataframe f_df.\n",
    "f_df = pd.read_csv(path_files)\n",
    "\n",
    "# Read the locus (and wall) CSV into dataframe l_df.\n",
    "l_df = pd.read_csv(path_loci)\n",
    "\n",
    "# Set up a dict for File and Locus (and Wall) associations.\n",
    "file_locus_data = {\n",
    "    'File ID':[], \n",
    "    'Locus ID': [],\n",
    "}\n",
    "\n",
    "# Set up a dict for File and Area associations.\n",
    "# NOTE: An \"Area\" is an aggregation of multiple squares in the locus/wall\n",
    "# datafile. Eric grouped these to make search / browsing easier. They\n",
    "# don't really have any purpose or value for interpretation.\n",
    "file_square_data = {\n",
    "    'File ID':[], \n",
    "    'Area': [],\n",
    "}\n",
    "\n",
    "\n",
    "def add_to_file_context_data(\n",
    "    file_ids, \n",
    "    context_ids,  \n",
    "    data,\n",
    "    context_id_col='Locus ID'\n",
    "):\n",
    "    \"\"\"Adds records of file and context associations to a data dict\"\"\"\n",
    "    if not isinstance(context_ids, list):\n",
    "        context_ids = [context_ids]\n",
    "    # Get the cross product of all the file_ids and the\n",
    "    # context_ids\n",
    "    crossprod = list(itertools.product(file_ids, context_ids))\n",
    "    data['File ID'] += [c[0] for c in crossprod]\n",
    "    data[context_id_col] += [c[1] for c in crossprod]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File ID</th>\n",
       "      <th>Illustration</th>\n",
       "      <th>Chp</th>\n",
       "      <th>Part Number</th>\n",
       "      <th>Caption</th>\n",
       "      <th>DB ID</th>\n",
       "      <th>FileName</th>\n",
       "      <th>FileType</th>\n",
       "      <th>Error in print</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Figure 1.1</td>\n",
       "      <td>Figure</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fig. 1.1. Map of Tel Dor showing Area G in rel...</td>\n",
       "      <td>d09Z1-1001</td>\n",
       "      <td>d09Z1-1001.tif</td>\n",
       "      <td>tif</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Figure 1.2</td>\n",
       "      <td>Figure</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Fig. 1.2. A reconstruction of the Roman street...</td>\n",
       "      <td>d09Z1-1002</td>\n",
       "      <td>d09Z1-1002.tif</td>\n",
       "      <td>tif</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Figure 1.3</td>\n",
       "      <td>Figure</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Fig. 1.3. Area G during the first season in 19...</td>\n",
       "      <td>p08Z3-1365</td>\n",
       "      <td>p08Z3-1365.tif</td>\n",
       "      <td>tif</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      File ID Illustration  Chp Part Number  \\\n",
       "0  Figure 1.1       Figure  1.0           1   \n",
       "1  Figure 1.2       Figure  1.0           2   \n",
       "2  Figure 1.3       Figure  1.0           3   \n",
       "\n",
       "                                             Caption       DB ID  \\\n",
       "0  Fig. 1.1. Map of Tel Dor showing Area G in rel...  d09Z1-1001   \n",
       "1  Fig. 1.2. A reconstruction of the Roman street...  d09Z1-1002   \n",
       "2  Fig. 1.3. Area G during the first season in 19...  p08Z3-1365   \n",
       "\n",
       "         FileName FileType Error in print  \n",
       "0  d09Z1-1001.tif      tif            NaN  \n",
       "1  d09Z1-1002.tif      tif            NaN  \n",
       "2  p08Z3-1365.tif      tif            NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Site</th>\n",
       "      <th>Area</th>\n",
       "      <th>Note</th>\n",
       "      <th>Locus ID</th>\n",
       "      <th>Original Sort Order</th>\n",
       "      <th>Locus/Wall</th>\n",
       "      <th>Number</th>\n",
       "      <th>Square</th>\n",
       "      <th>Phase</th>\n",
       "      <th>Contextual Integrity (I) Code</th>\n",
       "      <th>Contextual Integrity (I)</th>\n",
       "      <th>Phasing of Contents (PoC)</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Context</th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Israel</td>\n",
       "      <td>Tel Dor</td>\n",
       "      <td>AI–AK:31–32</td>\n",
       "      <td>To facilitate navigation, Open Context editors...</td>\n",
       "      <td>Locus 9000</td>\n",
       "      <td>1</td>\n",
       "      <td>Locus</td>\n",
       "      <td>9000</td>\n",
       "      <td>AI–AK/31–32</td>\n",
       "      <td>1a</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>⪰1</td>\n",
       "      <td>Topsoil on top of ashlar pavement of Phase 1a ...</td>\n",
       "      <td>--</td>\n",
       "      <td>Dor IIIA: 5, 7, 8, 9, 11, 12, 13, 16</td>\n",
       "      <td>Not Final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Israel</td>\n",
       "      <td>Tel Dor</td>\n",
       "      <td>AJ:30–34</td>\n",
       "      <td>To facilitate navigation, Open Context editors...</td>\n",
       "      <td>Locus 9001</td>\n",
       "      <td>2</td>\n",
       "      <td>Locus</td>\n",
       "      <td>9001</td>\n",
       "      <td>AJ/32</td>\n",
       "      <td>1a</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>⪰1</td>\n",
       "      <td>Topsoil down to fragment of F9000</td>\n",
       "      <td>--</td>\n",
       "      <td>Dor IIIA: 12</td>\n",
       "      <td>Not Final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Israel</td>\n",
       "      <td>Tel Dor</td>\n",
       "      <td>AJ:30–34</td>\n",
       "      <td>To facilitate navigation, Open Context editors...</td>\n",
       "      <td>Locus 9002</td>\n",
       "      <td>3</td>\n",
       "      <td>Locus</td>\n",
       "      <td>9002</td>\n",
       "      <td>AJ/33</td>\n",
       "      <td>--</td>\n",
       "      <td>n</td>\n",
       "      <td>non-stratified</td>\n",
       "      <td>--</td>\n",
       "      <td>Topsoil</td>\n",
       "      <td>--</td>\n",
       "      <td>Dor IIIA: 13</td>\n",
       "      <td>Not Final</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Region     Site         Area  \\\n",
       "0  Israel  Tel Dor  AI–AK:31–32   \n",
       "1  Israel  Tel Dor     AJ:30–34   \n",
       "2  Israel  Tel Dor     AJ:30–34   \n",
       "\n",
       "                                                Note    Locus ID  \\\n",
       "0  To facilitate navigation, Open Context editors...  Locus 9000   \n",
       "1  To facilitate navigation, Open Context editors...  Locus 9001   \n",
       "2  To facilitate navigation, Open Context editors...  Locus 9002   \n",
       "\n",
       "   Original Sort Order Locus/Wall Number       Square Phase  \\\n",
       "0                    1      Locus   9000  AI–AK/31–32    1a   \n",
       "1                    2      Locus   9001        AJ/32    1a   \n",
       "2                    3      Locus   9002        AJ/33    --   \n",
       "\n",
       "  Contextual Integrity (I) Code Contextual Integrity (I)  \\\n",
       "0                            --                       --   \n",
       "1                            --                       --   \n",
       "2                             n           non-stratified   \n",
       "\n",
       "  Phasing of Contents (PoC)  \\\n",
       "0                        ⪰1   \n",
       "1                        ⪰1   \n",
       "2                        --   \n",
       "\n",
       "                                            Comments Context  \\\n",
       "0  Topsoil on top of ashlar pavement of Phase 1a ...      --   \n",
       "1                  Topsoil down to fragment of F9000      --   \n",
       "2                                            Topsoil      --   \n",
       "\n",
       "                                 Chapter     Status  \n",
       "0   Dor IIIA: 5, 7, 8, 9, 11, 12, 13, 16  Not Final  \n",
       "1                           Dor IIIA: 12  Not Final  \n",
       "2                           Dor IIIA: 13  Not Final  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 3 for Wall 9003 as W9003\n",
      "Found: 1 for Wall 9015 as W9015\n",
      "Found: 1 for Wall 9019 as W9019\n",
      "Found: 2 for Locus 9025 as L9025\n",
      "Found: 1 for Wall 9041 as W9041\n",
      "Found: 1 for Wall 9047 as W9047\n",
      "Found: 2 for Locus 9048 as L9048\n",
      "Found: 3 for Wall 9058 as W9058\n",
      "Found: 5 for Wall 9065 as W9065\n",
      "Found: 14 for Wall 9066 as W9066\n",
      "Found: 3 for Wall 9096 as W9096\n",
      "Found: 4 for Wall 9147 as W9147\n",
      "Found: 2 for Wall 9162 as W9162\n",
      "Found: 3 for Locus 9168 as L9168\n",
      "Found: 2 for Wall 9180 as W9180\n",
      "Found: 1 for Locus 9185 as L9185\n",
      "Found: 1 for Locus 9202 as L9202\n",
      "Found: 2 for Locus 9204 as L9204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python-3-7-4\\lib\\site-packages\\pandas\\core\\strings.py:1843: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found: 21 for Wall 9211 as W9211\n",
      "Found: 2 for Wall 9212 as W9212\n",
      "Found: 6 for Wall 9216 as W9216\n",
      "Found: 2 for Wall 9217 as W9217\n",
      "Found: 1 for Wall 9243 as W9243\n",
      "Found: 2 for Locus 9251 as L9251\n",
      "Found: 1 for Wall 9253 as W9253\n",
      "Found: 30 for Wall 9262 as W9262\n",
      "Found: 30 for Wall 9266 as W9266\n",
      "Found: 1 for Wall 9274 as W9274\n",
      "Found: 1 for Wall 9275a–b as W9275a–b\n",
      "Found: 7 for Wall 9278 as W9278\n",
      "Found: 1 for Wall 9279 as W9279\n",
      "Found: 10 for Wall 9282 as W9282\n",
      "Found: 1 for Wall 9290 as W9290\n",
      "Found: 1 for Locus 9298 as L9298\n",
      "Found: 1 for Wall 9301b as W9301b\n",
      "Found: 2 for Locus 9326 as L9326\n",
      "Found: 1 for Wall 9340 as W9340\n",
      "Found: 1 for Locus 9346 as L9346\n",
      "Found: 7 for Wall 9400 as W9400\n",
      "Found: 4 for Wall 9408a as W9408a\n",
      "Found: 7 for Wall 9408b as W9408b\n",
      "Found: 1 for Wall 9412 as W9412\n",
      "Found: 3 for Wall 9413 as W9413\n",
      "Found: 1 for Locus 9434 as L9434\n",
      "Found: 1 for Wall 9466 as W9466\n",
      "Found: 1 for Wall 9490 as W9490\n",
      "Found: 1 for Wall 9491 as W9491\n",
      "Found: 4 for Wall 9510 as W9510\n",
      "Found: 1 for Locus 9550 as L9550\n",
      "Found: 1 for Locus 9558 as L9558\n",
      "Found: 1 for Wall 9560 as W9560\n",
      "Found: 14 for Wall 9626 as W9626\n",
      "Found: 1 for Locus 9630 as L9630\n",
      "Found: 6 for Wall 9636 as W9636\n",
      "Found: 4 for Locus 9658 as L9658\n",
      "Found: 1 for Locus 9660 as L9660\n",
      "Found: 1 for Locus 9669 as L9669\n",
      "Found: 3 for Wall 9675 as W9675\n",
      "Found: 1 for Locus 9679 as L9679\n",
      "Found: 1 for Locus 9680 as L9680\n",
      "Found: 19 for Wall 9684 as W9684\n",
      "Found: 1 for Locus 9698 as L9698\n",
      "Found: 3 for Wall 9702 as W9702\n",
      "Found: 13 for Wall 9704 as W9704\n",
      "Found: 1 for Locus 9714 as L9714\n",
      "Found: 6 for Wall 9715 as W9715\n",
      "Found: 13 for Wall 9728 as W9728\n",
      "Found: 15 for Wall 9729 as W9729\n",
      "Found: 6 for Wall 9735 as W9735\n",
      "Found: 1 for Locus 9736 as L9736\n",
      "Found: 1 for Locus 9752 as L9752\n",
      "Found: 1 for Locus 9762 as L9762\n",
      "Found: 1 for Locus 9766 as L9766\n",
      "Found: 1 for Locus 9779 as L9779\n",
      "Found: 4 for Wall 9800 as W9800\n",
      "Found: 2 for Locus 9805 as L9805\n",
      "Found: 1 for Locus 9816 as L9816\n",
      "Found: 4 for Wall 9825 as W9825\n",
      "Found: 3 for Wall 9841 as W9841\n",
      "Found: 1 for Wall 9845 as W9845\n",
      "Found: 1 for Locus 9865 as L9865\n",
      "Found: 2 for Locus 9871 as L9871\n",
      "Found: 1 for Locus 9875 as L9875\n",
      "Found: 7 for Locus 9880 as L9880\n",
      "Found: 2 for Locus 9882 as L9882\n",
      "Found: 2 for Wall 9885 as W9885\n",
      "Found: 5 for Wall 9887 as W9887\n",
      "Found: 2 for Locus 9890 as L9890\n",
      "Found: 1 for Locus 9895 as L9895\n",
      "Found: 1 for Locus 9903 as L9903\n",
      "Found: 2 for Wall 9904 as W9904\n",
      "Found: 9 for Wall 9909 as W9909\n",
      "Found: 8 for Wall 9914 as W9914\n",
      "Found: 14 for Wall 9915 as W9915\n",
      "Found: 1 for Wall 9917 as W9917\n",
      "Found: 5 for Wall 9936 as W9936\n",
      "Found: 1 for Wall 9942 as W9942\n",
      "Found: 1 for Wall 9943 as W9943\n",
      "Found: 2 for Wall 9952 as W9952\n",
      "Found: 11 for Wall 9957 as W9957\n",
      "Found: 2 for Wall 9959 as W9959\n",
      "Found: 3 for Wall 9961 as W9961\n",
      "Found: 6 for Wall 9963 as W9963\n",
      "Found: 5 for Wall 9964 as W9964\n",
      "Found: 1 for Locus 9965 as L9965\n",
      "Found: 1 for Wall 9970 as W9970\n",
      "Found: 1 for Locus 9974 as L9974\n",
      "Found: 2 for Wall 9975 as W9975\n",
      "Found: 9 for Locus 9982 as L9982\n",
      "Found: 1 for Locus 9985 as L9985\n",
      "Found: 4 for Wall 9989 as W9989\n",
      "Found: 8 for Wall 9990 as W9990\n",
      "Found: 3 for Wall 9993 as W9993\n",
      "Found: 1 for Wall 9998 as W9998\n",
      "Found: 1 for Locus 18000 as L18000\n",
      "Found: 3 for Wall 18010a as W18010a\n",
      "Found: 1 for Locus 18030 as L18030\n",
      "Found: 9 for Locus 18033 as L18033\n",
      "Found: 1 for Locus 18034 as L18034\n",
      "Found: 1 for Locus 18035 as L18035\n",
      "Found: 1 for Locus 18036 as L18036\n",
      "Found: 1 for Locus 18041 as L18041\n",
      "Found: 12 for Wall 18045 as W18045\n",
      "Found: 19 for Wall 18048 as W18048\n",
      "Found: 1 for Locus 18054 as L18054\n",
      "Found: 1 for Locus 18059 as L18059\n",
      "Found: 1 for Locus 18065 as L18065\n",
      "Found: 2 for Locus 18067 as L18067\n",
      "Found: 1 for Locus 18075 as L18075\n",
      "Found: 1 for Locus 18082 as L18082\n",
      "Found: 1 for Locus 18088 as L18088\n",
      "Found: 2 for Locus 18089 as L18089\n",
      "Found: 1 for Locus 18107 as L18107\n",
      "Found: 1 for Locus 18121 as L18121\n",
      "Found: 1 for Locus 18137 as L18137\n",
      "Found: 1 for Locus 18153 as L18153\n",
      "Found: 1 for Locus 18154 as L18154\n",
      "Found: 2 for Locus 18182 as L18182\n",
      "Found: 1 for Locus 18199 as L18199\n",
      "Found: 1 for Locus 18205 as L18205\n",
      "Found: 1 for Wall 18206 as W18206\n",
      "Found: 1 for Locus 18213 as L18213\n",
      "Found: 1 for Locus 18216 as L18216\n",
      "Found: 1 for Wall 18218 as W18218\n",
      "Found: 1 for Locus 18225 as L18225\n",
      "Found: 22 for Wall 18229 as W18229\n",
      "Found: 1 for Locus 18239 as L18239\n",
      "Found: 2 for Locus 18241 as L18241\n",
      "Found: 1 for Locus 18242 as L18242\n",
      "Found: 1 for Locus 18243 as L18243\n",
      "Found: 1 for Wall 18248 as W18248\n",
      "Found: 9 for Wall 18250 as W18250\n",
      "Found: 1 for Locus 18255 as L18255\n",
      "Found: 5 for Locus 18275 as L18275\n",
      "Found: 3 for Locus 18286 as L18286\n",
      "Found: 3 for Locus 18293 as L18293\n",
      "Found: 6 for Wall 18296 as W18296\n",
      "Found: 3 for Locus 18298 as L18298\n",
      "Found: 1 for Wall 18300 as W18300\n",
      "Found: 7 for Locus 18308 as L18308\n",
      "Found: 1 for Locus 18312 as L18312\n",
      "Found: 1 for Locus 18313 as L18313\n",
      "Found: 7 for Wall 18315 as W18315\n",
      "Found: 1 for Locus 18319 as L18319\n",
      "Found: 1 for Locus 18324 as L18324\n",
      "Found: 2 for Locus 18330 as L18330\n",
      "Found: 9 for Locus 18333 as L18333\n",
      "Found: 3 for Locus 18347 as L18347\n",
      "Found: 8 for Wall 18349 as W18349\n",
      "Found: 1 for Locus 18361 as L18361\n",
      "Found: 2 for Locus 18363 as L18363\n",
      "Found: 1 for Locus 18380 as L18380\n",
      "Found: 2 for Locus 18399 as L18399\n",
      "Found: 1 for Locus 18400 as L18400\n",
      "Found: 2 for Wall 18463 as W18463\n",
      "Found: 2 for Wall 18471 as W18471\n",
      "Found: 9 for Wall 18481 as W18481\n",
      "Found: 1 for Locus 18482 as L18482\n",
      "Found: 2 for Wall 18503 as W18503\n",
      "Found: 2 for Locus 18509 as L18509\n",
      "Found: 2 for Wall 18514 as W18514\n",
      "Found: 5 for Wall 18515 as W18515\n",
      "Found: 2 for Wall 18516 as W18516\n",
      "Found: 1 for Wall 18528 as W18528\n",
      "Found: 1 for Locus 18529 as L18529\n",
      "Found: 3 for Locus 18570 as L18570\n",
      "Found: 2 for Wall 18575 as W18575\n",
      "Found: 2 for Wall 18577 as W18577\n",
      "Found: 1 for Locus 18584 as L18584\n",
      "Found: 2 for Wall 18912 as W18912\n",
      "Found: 1 for Locus 04G0-004 as L04G0-004\n",
      "Found: 1 for Wall 04G0-008 as W04G0-008\n",
      "File and Locus Associations (Found: 680)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Find matching Loci (including Wall Loci) by matching their IDs\n",
    "# with text in the file metadata 'Caption' column.\n",
    "for locus_wall_id in l_df['Locus ID'].unique().tolist():\n",
    "    l_w_id = locus_wall_id.replace('Locus ', 'L').replace('Wall ', 'W')\n",
    "    \n",
    "    # l_w_mum_id is for locus or wall IDs that are long unlikely to be\n",
    "    # a false positive, and lack a \"L\" or \"W\" in the caption.\n",
    "    l_w_num_id = l_w_id.replace('L', ' ').replace('W', ' ')\n",
    "    if len(l_w_num_id) >= 6:\n",
    "        # Catch cases where the Locus / Wall ID is long like \n",
    "        # '18347'.\n",
    "        l_w_indx = (\n",
    "            f_df['Caption'].str.contains(l_w_id)\n",
    "            | f_df['Caption'].str.contains(l_w_num_id)\n",
    "        )\n",
    "    else:\n",
    "        # The locus / wall id is too short to trust without a \n",
    "        # \"L\" or \"W\" prefix.\n",
    "        l_w_indx = f_df['Caption'].str.contains(l_w_id)\n",
    "    \n",
    "    if f_df[l_w_indx].empty:\n",
    "        # We didn't find a match, so continue.\n",
    "        continue\n",
    "    print('Found: {} for {} as {}'.format(\n",
    "            len(f_df[l_w_indx]), \n",
    "            locus_wall_id,\n",
    "            l_w_id,\n",
    "        )\n",
    "    )\n",
    "    file_ids = f_df[l_w_indx]['File ID'].unique().tolist()\n",
    "    file_locus_data = add_to_file_context_data(\n",
    "        file_ids, \n",
    "        locus_wall_id, \n",
    "        file_locus_data\n",
    "    )\n",
    "\n",
    "# Now make a dataframe of the file - locus associations\n",
    "file_locus_df = pd.DataFrame(data=file_locus_data)\n",
    "print('File and Locus Associations (Found: {})'.format(\n",
    "    len(file_locus_df.index))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 22 files with square AJ/32 and 1 areas\n",
      "Found: 14 files with square AJ/33 and 1 areas\n",
      "Found: 3 files with square AJ–AK/33 and 1 areas\n",
      "Found: 22 files with square AI/32 and 1 areas\n",
      "Found: 1 files with square AJ/31 and 1 areas\n",
      "Found: 20 files with square AI/31 and 1 areas\n",
      "Found: 1 files with square AI/31–32 and 1 areas\n",
      "Found: 1 files with square AI/31–33 and 1 areas\n",
      "Found: 4 files with square AJ/32–33 and 1 areas\n",
      "Found: 12 files with square AK/32 and 1 areas\n",
      "Found: 6 files with square AJ/34 and 1 areas\n",
      "Found: 26 files with square AI/33 and 1 areas\n",
      "Found: 9 files with square AJ–AK/32 and 1 areas\n",
      "Found: 1 files with square AI/34 and 1 areas\n",
      "Found: 6 files with square AH/33 and 1 areas\n",
      "Found: 5 files with square AK/33 and 1 areas\n",
      "Found: 2 files with square AK/34 and 1 areas\n",
      "Found: 4 files with square AH/34 and 1 areas\n",
      "Found: 3 files with square AI–AJ/32 and 1 areas\n",
      "Found: 1 files with square AI–AJ/33 and 1 areas\n",
      "Found: 8 files with square AH–AI/33 and 1 areas\n",
      "Found: 1 files with square AI/33–34 and 1 areas\n",
      "Found: 1 files with square AG/34 and 1 areas\n",
      "Found: 11 files with square AG/33 and 1 areas\n",
      "Found: 1 files with square AK/32–33 and 1 areas\n",
      "Found: 2 files with square AG/33–34 and 1 areas\n",
      "Found: 1 files with square AI–AJ/32–33 and 1 areas\n",
      "File and Area Associations (Found: 188)\n"
     ]
    }
   ],
   "source": [
    "# Find matching Loci (including Wall Loci) by matching their Squares\n",
    "# with text in the file metadata 'Caption' column.\n",
    "l_df_sq = l_df[~l_df['Square'].isnull()]\n",
    "for square in l_df_sq['Square'].astype(str).unique().tolist():\n",
    "    sq_indx = f_df['Caption'].str.contains(square)\n",
    "    if len(square) < 3 or f_df[sq_indx].empty:\n",
    "        # Not enough characters for secure match.\n",
    "        continue\n",
    "    # Get all file_ids that have his square in their captions\n",
    "    file_ids = f_df[sq_indx]['File ID'].unique().tolist()\n",
    "    # Get all the locus ids that are associated with this square\n",
    "    area_ids = l_df[\n",
    "        l_df['Square']==square\n",
    "    ]['Area'].unique().tolist()\n",
    "    print('Found: {} files with square {} and {} areas'.format(\n",
    "            len(f_df[sq_indx]), \n",
    "            square,\n",
    "            len(area_ids)\n",
    "        )\n",
    "    )\n",
    "    # Now add to the file_locus_data.\n",
    "    file_square_data = add_to_file_context_data(\n",
    "        file_ids, \n",
    "        area_ids, \n",
    "        file_square_data,\n",
    "        context_id_col='Area'\n",
    "    )\n",
    "\n",
    "# Now make a dataframe of the file - area associations\n",
    "file_area_df = pd.DataFrame(data=file_square_data)\n",
    "print('File and Area Associations (Found: {})'.format(\n",
    "    len(file_area_df.index))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found File and Context Associations for 426 unique files (total rows: 857)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File ID</th>\n",
       "      <th>Site Area</th>\n",
       "      <th>Area</th>\n",
       "      <th>Locus ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Figure 1.1</td>\n",
       "      <td>Area G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>Figure 1.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AJ:30–34</td>\n",
       "      <td>Wall 9914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>Figure 1.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AI–AJ:32–34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         File ID Site Area         Area   Locus ID\n",
       "0     Figure 1.1    Area G          NaN        NaN\n",
       "532  Figure 1.10       NaN     AJ:30–34  Wall 9914\n",
       "733  Figure 1.11       NaN  AI–AJ:32–34        NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_df = pd.merge(file_locus_df, file_area_df, on='File ID', how='outer')\n",
    "context_linked_files = context_df['File ID'].unique().tolist()\n",
    "print('Found File and Context Associations for {} unique files (total rows: {})'.format(\n",
    "    len(context_linked_files),\n",
    "    len(context_df.index))\n",
    ")\n",
    "\n",
    "\n",
    "# Get a list of files that do NOT have context associations\n",
    "no_context_files = f_df[\n",
    "    ~f_df['File ID'].isin(context_linked_files)\n",
    "]['File ID'].unique().tolist()\n",
    "\n",
    "file_site_data = {\n",
    "    'File ID':[], \n",
    "    'Site Area': [],\n",
    "}\n",
    "file_site_data = add_to_file_context_data(\n",
    "    no_context_files, \n",
    "    'Area G', \n",
    "    file_site_data,\n",
    "    context_id_col='Site Area'\n",
    ")\n",
    "site_df = pd.DataFrame(data=file_site_data)\n",
    "context_df = pd.concat([context_df, site_df], sort=False)\n",
    "\n",
    "# Set the column order for nice aesthetics\n",
    "context_df = context_df[['File ID', 'Site Area', 'Area', 'Locus ID']]\n",
    "context_df.sort_values(by=['File ID', 'Locus ID', 'Area'], inplace=True)\n",
    "\n",
    "context_df.to_csv(path_files_contexts, index=False)\n",
    "context_df.head(3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
