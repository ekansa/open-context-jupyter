{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look for Wall 18839 or Locus 18839\n",
      "Look for Wall 18229 or Locus 18229\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\python-3-7-4\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2892\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2893\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2894\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: False",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-10c52d29d97c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mup_indx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfl_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Locus_Wall'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Locus_Wall'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mfl_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mup_indx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Locus ID'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid_indx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Locus ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Update {} with {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Locus_Wall'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid_indx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Locus ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python-3-7-4\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2986\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2987\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2988\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2989\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2990\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python-3-7-4\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2893\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2897\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: False"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Get the root_path for this jupyter notebook repo.\n",
    "repo_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "\n",
    "path_files_locus_index = os.path.join(\n",
    "    repo_path, 'files', 'tell-dor', 'tell-dor-area-g-locus-image-index.csv'\n",
    ")\n",
    "\n",
    "# Path to the Tell Dor file metadata CSV\n",
    "path_files = os.path.join(\n",
    "    repo_path, 'files', 'tell-dor', 'tell-dor-files.csv'\n",
    ")\n",
    "# Path to the Tell Dor locus metadata CSV \n",
    "path_loci = os.path.join(\n",
    "    repo_path, 'files', 'tell-dor', 'tell-dor-loci.csv'\n",
    ")\n",
    "# Output path for associations between the files and the loci.\n",
    "path_files_contexts = os.path.join(\n",
    "    repo_path, 'files', 'tell-dor', 'tell-dor-files-contexts.csv'\n",
    ")\n",
    "\n",
    "\n",
    "# Read the file - locus index supplied by the Tell Dor team.\n",
    "fl_df = pd.read_csv(path_files_locus_index)\n",
    "\n",
    "# Read the file metadata CSV into dataframe f_df.\n",
    "f_df = pd.read_csv(path_files)\n",
    "\n",
    "# Read the locus (and wall) CSV into dataframe l_df.\n",
    "l_df = pd.read_csv(path_loci)\n",
    "\n",
    "fl_df['Locus_Wall'] = fl_df['Locus_Wall'].astype(str) \n",
    "fl_df['Locus ID'] = np.nan\n",
    "for i, row in fl_df.iterrows():\n",
    "    wall_id = 'Wall ' + row['Locus_Wall']\n",
    "    locus_id = 'Locus ' + row['Locus_Wall']\n",
    "    print('Look for {} or {}'.format(wall_id, locus_id))\n",
    "    id_indx = ((l_df['Locus ID']==wall_id)|(l_df['Locus ID']==locus_id))\n",
    "    if l_df[id_indx].empty:\n",
    "        continue\n",
    "    up_indx = (fl_df['Locus_Wall'] == row['Locus_Wall'])\n",
    "    fl_df.loc[up_indx, 'Locus ID'] = l_df[id_indx]['Locus ID'].iloc[0]\n",
    "    print('Update {} with {}'.format(row['Locus_Wall'], l_df[id_indx]['Locus ID'].iloc[0]))\n",
    "\n",
    "fl_df.to_csv(path_files_locus_index, index=False)\n",
    "\n",
    "\n",
    "\n",
    "# Set up a dict for File and Locus (and Wall) associations.\n",
    "file_locus_data = {\n",
    "    'File ID':[], \n",
    "    'Locus ID': [],\n",
    "}\n",
    "\n",
    "# Set up a dict for File and Area associations.\n",
    "# NOTE: An \"Area\" is an aggregation of multiple squares in the locus/wall\n",
    "# datafile. Eric grouped these to make search / browsing easier. They\n",
    "# don't really have any purpose or value for interpretation.\n",
    "file_square_data = {\n",
    "    'File ID':[], \n",
    "    'Area': [],\n",
    "}\n",
    "\n",
    "\n",
    "def add_to_file_context_data(\n",
    "    file_ids, \n",
    "    context_ids,  \n",
    "    data,\n",
    "    context_id_col='Locus ID'\n",
    "):\n",
    "    \"\"\"Adds records of file and context associations to a data dict\"\"\"\n",
    "    if not isinstance(context_ids, list):\n",
    "        context_ids = [context_ids]\n",
    "    # Get the cross product of all the file_ids and the\n",
    "    # context_ids\n",
    "    crossprod = list(itertools.product(file_ids, context_ids))\n",
    "    data['File ID'] += [c[0] for c in crossprod]\n",
    "    data[context_id_col] += [c[1] for c in crossprod]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find matching Loci (including Wall Loci) by matching their IDs\n",
    "# with text in the file metadata 'Caption' column.\n",
    "for locus_wall_id in l_df['Locus ID'].unique().tolist():\n",
    "    l_w_id = locus_wall_id.replace('Locus ', 'L').replace('Wall ', 'W')\n",
    "    \n",
    "    # l_w_mum_id is for locus or wall IDs that are long unlikely to be\n",
    "    # a false positive, and lack a \"L\" or \"W\" in the caption.\n",
    "    l_w_num_id = l_w_id.replace('L', ' ').replace('W', ' ')\n",
    "    if len(l_w_num_id) >= 6:\n",
    "        # Catch cases where the Locus / Wall ID is long like \n",
    "        # '18347'.\n",
    "        l_w_indx = (\n",
    "            f_df['Caption'].str.contains(l_w_id)\n",
    "            | f_df['Caption'].str.contains(l_w_num_id)\n",
    "        )\n",
    "    else:\n",
    "        # The locus / wall id is too short to trust without a \n",
    "        # \"L\" or \"W\" prefix.\n",
    "        l_w_indx = f_df['Caption'].str.contains(l_w_id)\n",
    "    \n",
    "    if f_df[l_w_indx].empty:\n",
    "        # We didn't find a match, so continue.\n",
    "        continue\n",
    "    print('Found: {} for {} as {}'.format(\n",
    "            len(f_df[l_w_indx]), \n",
    "            locus_wall_id,\n",
    "            l_w_id,\n",
    "        )\n",
    "    )\n",
    "    file_ids = f_df[l_w_indx]['File ID'].unique().tolist()\n",
    "    file_locus_data = add_to_file_context_data(\n",
    "        file_ids, \n",
    "        locus_wall_id, \n",
    "        file_locus_data\n",
    "    )\n",
    "\n",
    "# Now make a dataframe of the file - locus associations\n",
    "file_locus_df = pd.DataFrame(data=file_locus_data)\n",
    "print('File and Locus Associations (Found: {})'.format(\n",
    "    len(file_locus_df.index))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find matching Loci (including Wall Loci) by matching their Squares\n",
    "# with text in the file metadata 'Caption' column.\n",
    "l_df_sq = l_df[~l_df['Square'].isnull()]\n",
    "for square in l_df_sq['Square'].astype(str).unique().tolist():\n",
    "    sq_indx = f_df['Caption'].str.contains(square)\n",
    "    if len(square) < 3 or f_df[sq_indx].empty:\n",
    "        # Not enough characters for secure match.\n",
    "        continue\n",
    "    # Get all file_ids that have his square in their captions\n",
    "    file_ids = f_df[sq_indx]['File ID'].unique().tolist()\n",
    "    # Get all the locus ids that are associated with this square\n",
    "    area_ids = l_df[\n",
    "        l_df['Square']==square\n",
    "    ]['Area'].unique().tolist()\n",
    "    print('Found: {} files with square {} and {} areas'.format(\n",
    "            len(f_df[sq_indx]), \n",
    "            square,\n",
    "            len(area_ids)\n",
    "        )\n",
    "    )\n",
    "    # Now add to the file_locus_data.\n",
    "    file_square_data = add_to_file_context_data(\n",
    "        file_ids, \n",
    "        area_ids, \n",
    "        file_square_data,\n",
    "        context_id_col='Area'\n",
    "    )\n",
    "\n",
    "# Now make a dataframe of the file - area associations\n",
    "file_area_df = pd.DataFrame(data=file_square_data)\n",
    "print('File and Area Associations (Found: {})'.format(\n",
    "    len(file_area_df.index))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_df = pd.merge(file_locus_df, file_area_df, on='File ID', how='outer')\n",
    "context_linked_files = context_df['File ID'].unique().tolist()\n",
    "print('Found File and Context Associations for {} unique files (total rows: {})'.format(\n",
    "    len(context_linked_files),\n",
    "    len(context_df.index))\n",
    ")\n",
    "\n",
    "\n",
    "# Get a list of files that do NOT have context associations\n",
    "no_context_files = f_df[\n",
    "    ~f_df['File ID'].isin(context_linked_files)\n",
    "]['File ID'].unique().tolist()\n",
    "\n",
    "file_site_data = {\n",
    "    'File ID':[], \n",
    "    'Site Area': [],\n",
    "}\n",
    "file_site_data = add_to_file_context_data(\n",
    "    no_context_files, \n",
    "    'Area G', \n",
    "    file_site_data,\n",
    "    context_id_col='Site Area'\n",
    ")\n",
    "site_df = pd.DataFrame(data=file_site_data)\n",
    "context_df = pd.concat([context_df, site_df], sort=False)\n",
    "\n",
    "# Set the column order for nice aesthetics\n",
    "context_df = context_df[['File ID', 'Site Area', 'Area', 'Locus ID']]\n",
    "context_df.sort_values(by=['File ID', 'Locus ID', 'Area'], inplace=True)\n",
    "\n",
    "context_df.to_csv(path_files_contexts, index=False)\n",
    "context_df.head(3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
